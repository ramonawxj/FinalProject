---
title: "Final Project"
author: "Ramona Wu"
date: "2022-11-30"
output:
  html_document: default
  pdf_document: default
---
# Introduction
  Heart disease is one of the leading causes of death for people in the US. About half of all Americans (47%) have at least 1 of 3 key risk factors for heart disease: high blood pressure, high cholesterol, and smoking. In this project, we are interested in predicting whether a person can develop heart disease based on the known risk factors. The data set we used (originally coming from the CDC), Personal Key indicators of Heart Disease, is derived from the Behavioral Risk Factor Surveillance System (BRFSS), which conducts annual telephone surveys to gather data on the health status of US residents. It consisted of 401,958 rows and 279 columns originally, but for the purpose of predicting heart disease, only around 18 variables were left, which are believed to be the most relevant factors for the development of heart disease. The goal of this project is to fit the best possible machine learning model to the data set to predict whether or not a respondent has heart disease based on the given variables.

  In the Appendix there is a preview of the data set we used. It has 18 variables in total, including 17 predictors and 1 outcome variable. The predictors are BMI, smoking, alcohol drinking, stroke, physical health, mental health, difficulty walking, sex, age, race, diabetes, physical activity, health condition, sleep time, asthma, kidney disease, and skin cancer; and the outcome variable is heart disease. There are 2 graphs showing the distributions of the categorical and continuous variables. The respondents are more likely to have the following characteristics: no alcohol drinking, no history of asthma, no history of diabetes, no difficulty walking, no history of kidney disease, be physical active, be white, no history of skin cancer, no history of stroke, low mental health score, low physical health score, 7-8 hour sleep time, and BMI between 25-30 kg/m^2.
  
  In this project, we used the logistic regression, kNN, and the random forest methods to predict the outcome of developing heart disease. We used logistic regression as the first model, because the outcome variable is binary, and the log odds can be an appropriate estimate. kNN was the second model used. It is similar to bin smoothing, and it is easier to adapt to multiple dimensions. In real life, doctors determine a person's risk for developing heart diseases by asking questions, which is very much like a decision tree. Decision tree operates by predicting an outcome variable Y by partitioning the predictors.The random forest algorithm is a very popular machine learning approach that addresses the shortcoming of decision tree by averaging multiple decision trees, resulting in an improvement in prediction performance and reduction in instability. Random forest was the third algorithm used in this project.

# Results

## Logistic regression
  We partitioned the data set into train set and test set, where the train set was 90% and the test set was 10% of the data set. The fitted model showed that almost all the predictors (except for "AgeCategory25-29", "RaceOther", "RaceWhite", "DiabeticYes (during pregnancy)", and "PhysicalActivityYes") have a p-value of less than 0.05, indicating that these covariates are important predictors of the heart disease outcome.
  
  A regression coefficient describes the size and direction of the relationship between a predictor and the response variable. From the result table, we can see that higher BMI, smoking, history of stroke, bad physical health, bad mental health, difficulty walking, being a male, old age, history of diabetes, physical inactivity, bad health condition, history of asthma, history of kidney disease and history of skin cancer are associated with a higher possibility of developing heart disease. On the other hand, alcohol drinking (moderate) and longer sleeping time are associated with a lower risk of developing heart disease. If we look at categorical race, being Asian is the least likely to develop the outcome. More specifically, the risk of heart disease in descending order is Other, White, Hispanic, Black, Asian.

  We then used the test set and the confusion matrix to determine how accurate our model was. Even though the model has a high overall accuracy of 0.916, the sensitivity is relatively low (sensitivity = 0.106), and this is mainly because the prevalence of heart disease is low (p = 0.0855). The logistic regression model is much better than guessing, but other algorithms are probably better in this situation.
  
## kNN
  Similarly, we partitioned the data into training set and test set (9:1), and we fitted the kNN model based on the training set. We tried k (number of nearest neighbors) from 1- 101, and fitted a kNN model with the best tune.
  
  This kNN model improved the accuracy over the logistic regression, and the overall accuracy is 93.2%. However, from the confusion matrix, we can see that there is no prediction of "Outcome = 1", indicating a very low sensitivity. Even though the kNN model has a higher accuracy, it does not necessarily mean that it is a better model.
  
## Random forest
  For a classification problem, Breiman (2001) suggests mtry = p^0.5, where p is the number of descriptive features. In our case, p = 17^2 (4.12). Therefore, we experimented with mtry = 3, 4, and 5. The optimized model used a mtry value of 4.
  
  We also used the plot function to check whether we had run enough trees. ntree = 500 seemed to be a good choice, since the error did not decrease any further after around 200 tress.
  
  The overall prediction accuracy is 92.8%, which is higher than the logistic regression model and the kNN model. However, similarly, the sensitivity of this model is still low due to the low prevalance of incidence heart disease.
 
# Conclusion
  In this project, we fitted three different models to predict the outcome of developing heart disease. All three models have a high overall prediction accuracy (>90%), but the sensitivity is low. This might be due to the relatively low prevalence of the outcome. Out of the three models, the random forest is the most accurate, and the most similar to a doctor's diagnosis procedure, and thus is the most appropriate model. The logistic regression model is also very informative, since the magnitude of the coefficient implies the effect of the predictor, and the direction of the coefficient (positive or negative) implies whether the predictors are protective or detrimental.
  
  The analysis is successful. The overall prediction is high, and even though the sensitivity is not ideal, there is not much we can do to improve the sensitivity. If we had more time, we would fine tune the kNN and random forest models using a larger size of training data. If we could train these two models using as large a sample size as the logistic regression model, they might out compete the logistic model more. We can also do an ensemble by combining the results of different algorithm, for example, taking the average of the kNN and the random forest model to further improve the accuracy.

# References
Breiman, L. (2001), Random Forests, Machine Learning 45(1), 5-32.

Fryar CD, Chen T-C, Li X. Prevalence of uncontrolled risk factors for cardiovascular disease: United States, 1999â€“2010 pdf icon[PDF-494K]. NCHS data brief, no. 103. Hyattsville, MD: National Center for Health Statistics; 2012. 

Personal Key Indicators of Heart Disease
https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease
  
# Appendix
```{r}
library(tidyverse)
library(dslabs)
library(randomForest)
library(caret)
library(inspectdf)
setwd("~/Desktop/Folder/HSPH/Fall 2022/BST260/FinalProject")
dat <- read.csv("heart_2020_cleaned.csv")
head(dat)
dat |> inspect_cat() |> show_plot()
dat |> inspect_num() |> show_plot()
```

```{r}
set.seed(1997)

# generate data set for logistic regression
dat_glm <- dat |> mutate(Outcome = as.numeric(HeartDisease == "Yes")) 
dat_glm <- subset(dat_glm, select = -c(HeartDisease))

# generate training set and test set
y <- dat_glm$Outcome
test_index <- createDataPartition(y, times = 1, p = 0.1, list = FALSE)
dat_glm_train <- dat_glm |> slice(-test_index)
dat_glm_test <- dat_glm |> slice(test_index)

# logistic regression
glm_fit <- glm(Outcome~., family=binomial(link="logit"), data = dat_glm_train)
summary(glm_fit)
```

```{r}
# prediction using the test set
prediction1 <- predict(glm_fit, dat_glm_test, type = "response")
prediction2 <- ifelse(prediction1 > 0.5, 1, 0) |> factor()
cm <- confusionMatrix(prediction2, as.factor(dat_glm_test$Outcome))
cm$table
confusionMatrix(prediction2, as.factor(dat_glm_test$Outcome))$overall[["Accuracy"]] 
```
  
```{r}
# generate training set and test set for kNN
set.seed(1997)
dat_kNN <- dat |> mutate(Outcome = as.numeric(HeartDisease == "Yes")) 
dat_kNN <- subset(dat_kNN, select = -c(HeartDisease))
dat_kNN_train <- sample_n(dat_kNN, 2000)
dat_kNN_test <- sample_n(dat_kNN, 500)

# fit a kNN model and find the best tune
train_kNN <- train(as.factor(Outcome) ~ ., method = "knn", 
                   dat_kNN_train, 
                   tuneGrid = data.frame(k = seq(1, 101, 5))) 

train_kNN
```

```{r}
# fit the kNN model to the test data
prediction_kNN <- predict (train_kNN, newdata = dat_kNN_test)
cm2 <- confusionMatrix(prediction_kNN, as.factor(dat_kNN_test$Outcome))
cm2$table
confusionMatrix(prediction_kNN, as.factor(dat_kNN_test$Outcome))$overall[["Accuracy"]]
```
  
```{r}
# generate training set and test set for random forest
set.seed(1997)

dat_rf <- dat |> mutate(Outcome = as.numeric(HeartDisease == "Yes")) 
dat_rf<- subset(dat_rf, select = -c(HeartDisease))

dat_rf_train <- sample_n(dat_rf, 5000)
dat_rf_test <- sample_n(dat_rf, 500)
```

```{r}
# fit the random forest model
grid <- data.frame(mtry = c(3, 4, 5))
train_rf <- randomForest(as.factor(Outcome)~., data = dat_rf_train, tuneGrid = grid) 

train_rf
```

```{r}
# To check that we ran enough trees we can use the plot function
plot(train_rf)
```

```{r}
prediction_rf <- predict(train_rf, newdata = dat_rf_test)
cm3 <- confusionMatrix(prediction_rf, as.factor(dat_rf_test$Outcome))
cm3$table
confusionMatrix(prediction_rf, as.factor(dat_rf_test$Outcome))$overall[["Accuracy"]]
```
